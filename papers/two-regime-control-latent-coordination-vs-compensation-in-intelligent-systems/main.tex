\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}

% pandoc compatibility
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Unicode support for symbols present in the source
\DeclareUnicodeCharacter{2248}{\ensuremath{\approx}}

% Prevent automatic section numbering (headings already include explicit numbers)
\setcounter{secnumdepth}{0}

\begin{document}
\begin{titlepage}
\thispagestyle{empty}
\raggedright

\vspace*{0.62\textheight}

{\Large\bfseries Two-Regime Control: Latent Coordination vs Compensation in Intelligent Systems\par}
\vspace{0.4em}
{\large\itshape Robotics / Embodied AI\par}

\vspace{1.6em}

Tyson Jeffreys\\
Independent Researcher\\
\href{mailto:tyson@staygolden.dev}{tyson@staygolden.dev}

\vspace{1.6em}

Version 1.2 --- February 11, 2026

\end{titlepage}

\noindent\textbf{Series note (1/3).} This paper is Part 1 of a three-paper series on regime-level regulation in intelligent systems. Part 1 introduces a two-regime framing for embodied control (latent coordination vs.\ compensation) and proposes a measurable compensation index plus a slow baseline regulator layer. Part 2 extends the same regulation idea to representations via concept containers. Part 3 applies it to research systems via time-to-analysis and analysis-layer artifacts.\par\medskip
\hypertarget{abstract}{%
\subsection{Abstract}\label{abstract}}

Intelligent embodied systems often operate in two qualitatively different control regimes. In \textbf{latent coordination}, distributed dynamics (mechanics, morphology, low-level reflexes, and low-bandwidth feedback) do most of the work, yielding low energy use and robust behavior. In \textbf{compensation}, behavior is maintained through costly overrides: increased stiffness, gain escalation, frequent replanning, estimator churn, and high-frequency corrective action. We argue that many real-world failures in robotics and embodied AI arise not primarily from poor local controllers, but from the absence of an explicit mechanism to \textbf{detect and regulate prolonged residence in compensation}.

We formalize this framing using a measurable \textbf{compensation index} derived from actuator effort, control-rate, estimation uncertainty, contact instability, and override activity. We then propose a slow \textbf{baseline regulator layer} (â‰ˆ1--5 Hz) that biases the system back toward latent coordination without micromanaging task control. The resulting architecture predicts reduced energy per task, lower peak actuator stress, faster recovery from perturbation, and improved robustness under distribution shift. We provide concrete implementation patterns, falsifiable experiments, and negative tests.

\hypertarget{introduction}{%
\subsection{1. Introduction}\label{introduction}}

Modern robotics and embodied AI systems routinely achieve impressive performance in constrained environments, yet exhibit a recurring pattern outside their comfort zone: \textbf{excessive corrective action} that is energetically costly and brittle. This manifests as high torque/thermal stress, jerky trajectories, contact slip, frequent replanning, instability under perturbations, and degradation under battery/compute constraints.

A common response is to improve the local controller, estimator, or planner. These improvements help---but they often miss a deeper architectural issue: the system lacks an explicit representation of \textbf{how control is being achieved} at a given moment.

This paper proposes a regime-level lens:

\begin{itemize}
\tightlist
\item
  \textbf{Latent coordination:} the system is well-coupled; low-cost dynamics carry the task.
\item
  \textbf{Compensation:} the system is maintaining function through overrides and corrective contention.
\end{itemize}

Compensation is not ``bad.'' It is essential when resources drop or perturbations rise. The failure mode is \textbf{getting stuck} in compensation---quietly spending energy to hold together a system that is no longer coordinated.

Latent coordination is therefore a \textbf{supported regime}, not a willful state. When mechanical, estimator, or sensorimotor-coupling supports degrade, the system can preserve task output only by shifting into compensation. We refer to this transition pressure as a \textbf{support deficit}: insufficient structural support for low-cost coherence.

\hypertarget{two-control-regimes}{%
\subsection{2. Two Control Regimes}\label{two-control-regimes}}

\hypertarget{latent-coordination}{%
\subsubsection{2.1 Latent coordination}\label{latent-coordination}}

In latent coordination, behavior emerges from distributed alignment between:

\begin{itemize}
\tightlist
\item
  passive dynamics and morphology (compliance, inertial shaping)
\item
  stable low-level primitives (oscillators, impedance/reflex loops)
\item
  predictive coupling between sensing and actuation
\item
  low-bandwidth feedback and minimal correction
\end{itemize}

Operational signatures:

\begin{itemize}
\tightlist
\item
  low corrective torque and low control-rate
\item
  smooth trajectories; low jerk
\item
  stable contact with low slip
\item
  low estimator churn; uncertainty remains bounded
\item
  low override frequency from higher-level arbitration
\end{itemize}

Intuitively: the system is in an \textbf{efficient basin} where small errors self-correct with little ``fight.''

\hypertarget{compensation}{%
\subsubsection{2.2 Compensation}\label{compensation}}

In compensation, the system maintains function via corrective overrides:

\begin{itemize}
\tightlist
\item
  stiffness/gain escalation to suppress instability
\item
  higher-frequency corrections (controller ``chatter'')
\item
  replanning bursts and safety arbitration
\item
  aggressive sensing/estimation updates
\item
  contact stabilization by force rather than alignment
\end{itemize}

Operational signatures:

\begin{itemize}
\tightlist
\item
  elevated actuator effort and thermal stress
\item
  higher jerk or control derivative magnitude
\item
  increased estimator covariance / prediction error spikes
\item
  higher replanning/override duty cycle
\item
  constraint-violation corrections (slip, saturation, resets)
\end{itemize}

Intuitively: the system is ``holding together'' by spending energy on correction rather than benefiting from coordinated dynamics.

\hypertarget{formal-framing}{%
\subsection{3. Formal framing}\label{formal-framing}}

Let the embodied system have physical state \(s(t)\) (e.g., joint positions/velocities, base pose, contact state) and control \(u(t)\) (e.g., torques, target accelerations, motor commands). Let \(\pi\) denote the task policy (learned or engineered) and \(\mathcal{C}\) denote constraints (stability, safety, contacts, limits).

We separate control into a low-cost coordination component and a higher-cost override component:

\[
 u(t) = u_0(s(t), \pi) + \Delta u(t)
\]

\begin{itemize}
\tightlist
\item
  \(u_0\) is the nominal low-level controller / primitive stack.
\item
  \(\Delta u\) represents corrective overrides from arbitration, replanning, gain escalation, and emergency stabilization.
\end{itemize}

We hypothesize that regime membership is best characterized not by task success alone, but by \textbf{internal regulatory cost}: how much corrective contention is required to maintain behavior.

\hypertarget{a-measurable-compensation-index}{%
\subsection{4. A measurable compensation index}\label{a-measurable-compensation-index}}

We define a scalar \textbf{compensation index} \(C(t)\) as a weighted combination of measurable proxies:

\[
C(t) = w_\tau\,\|\tau(t)\|^2
+ w_{\dot u}\,\|\dot u(t)\|^2
+ w_{\Sigma}\,\operatorname{tr}(\Sigma(t))
+ w_{\text{plan}}\,r_{\text{plan}}(t)
+ w_{\text{slip}}\,r_{\text{slip}}(t)
+ w_{\text{sat}}\,r_{\text{sat}}(t)
+ w_{J}\,u_{J}(t)
\]

We treat learned \textbf{critics / judges} as \emph{telemetry sources}, not authorities. In many deployments there is no ground-truth verifier for ``is this action actually safe/efficient?'' in the moment. A useful posture is therefore: let critics contribute uncertainty signals, and let \textbf{abstention / tie mass} tighten posture rather than forcing a brittle choice.


where, depending on platform:

\begin{itemize}
\tightlist
\item
  \(\tau(t)\): joint torque vector (or motor current proxy)
\item
  \(\dot u(t)\): control derivative (or jerk proxy via commanded acceleration derivatives)
\item
  \(\Sigma(t)\): estimator covariance (or prediction error proxy)
\item
  \(r_{\text{plan}}(t)\): replanning / override rate (events per second)
\item
  \(r_{\text{slip}}(t)\): slip rate / contact instability metric
\item
  \(r_{\text{sat}}(t)\): actuator saturation / limit hits
\item
  \(u_{J}(t)\): abstention / tie mass from learned critics (e.g., probability that one or more monitors cannot confidently rank an action or classify a contact state); treat high \(u_{J}\) as epistemic uncertainty that should tighten posture.
\end{itemize}

\hypertarget{normalization}{%
\subsubsection{4.1 Normalization}\label{normalization}}

Raw units differ across terms. In practice, normalize each term by a baseline scale measured under stable operation:

\[
\tilde z(t) = \frac{z(t)}{\mathbb{E}[z\mid\text{stable}] + \epsilon}
\]

and compute \(C(t)\) using \(\tilde z\) to make weights interpretable.

\hypertarget{persistence-matters-filtered-index-and-duty-cycle}{%
\subsubsection{4.2 Persistence matters: filtered index and duty cycle}\label{persistence-matters-filtered-index-and-duty-cycle}}

Compensation is not an instantaneous value; the pathological mode is sustained residence.

Define a low-pass filtered index \(\bar C(t)\):

\[
\dot{\bar C}(t) = \frac{1}{\tau_c}(C(t) - \bar C(t))
\]

with \(\tau_c\) chosen to match ``regime timescale'' (e.g., 0.5--3 s).

Define a binary compensation indicator with hysteresis:

\[
H(t) = \begin{cases}
1 & \bar C(t) > \theta_{\uparrow} \\
0 & \bar C(t) < \theta_{\downarrow}
\end{cases}
\]

and the compensation duty cycle over a window \([t_0, t_1]\):

\[
\operatorname{DC}(t_0,t_1) = \frac{1}{t_1-t_0}\int_{t_0}^{t_1} H(t)\,dt
\]

Interpretation: - \(H(t)=1\) indicates the system is in compensation. - \(\operatorname{DC}\) measures how long it stays there.

\hypertarget{the-baseline-regulator-layer}{%
\subsection{5. The baseline regulator layer}\label{the-baseline-regulator-layer}}

We propose a slow regulator layer that shapes the system's operating posture without micromanaging task control.

\hypertarget{regulator-objective}{%
\subsubsection{5.1 Regulator objective}\label{regulator-objective}}

Let \(L_{\text{task}}(s,u)\) represent task loss or tracking error. The regulator introduces an internal cost that penalizes sustained compensation:

\[
J = \int_0^T \Big( L_{\text{task}}(s(t),u(t))
+ \lambda\,\phi(\bar C(t))
+ \gamma\,\|\dot{\bar C}(t)\|^2 \Big)\,dt
\]

\begin{itemize}
\tightlist
\item
  \(\phi\) is convex above a threshold (so high compensation is increasingly expensive).
\item
  \(\|\dot{\bar C}\|^2\) discourages thrash/oscillation.
\end{itemize}

\hypertarget{what-the-regulator-controls}{%
\subsubsection{5.2 What the regulator controls}\label{what-the-regulator-controls}}

The regulator acts on \textbf{meta-parameters} \(p(t)\) that modulate how the stack behaves:

\begin{itemize}
\tightlist
\item
  impedance / stiffness / damping gains
\item
  planner update rate and horizon
\item
  sensor polling rate and filter aggressiveness
\item
  safety margins and risk posture
\item
  ``reset / recenter'' routines (short stabilization protocols)
\end{itemize}

Critically: the regulator does not replace \(u_0\) or the planner; it biases them.

\hypertarget{a-simple-control-law}{%
\subsubsection{5.3 A simple control law}\label{a-simple-control-law}}

A practical regulator can be rule-based, learned, or hybrid. A minimal deterministic version:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Maintain a target band \([C^-, C^+]\) for \(\bar C\).
\item
  When \(\bar C\) rises persistently, invoke an \textbf{anti-compensation action} appropriate to the domain:

  \begin{itemize}
  \tightlist
  \item
    reduce unnecessary stiffness (when safe)
  \item
    reduce planner micromanagement rate
  \item
    execute a brief recenter routine (re-estimate, re-sync gait phase, settle posture)
  \item
    adjust gait/stance parameters toward stable manifold
  \end{itemize}
\item
  When \(\bar C\) returns to band, gradually relax posture back toward efficient settings.
\end{enumerate}

Pseudocode sketch:

\begin{verbatim}
if barC > C_plus for longer than T_high:
    p <- p + alpha * delta_up(barC)        # increase safety posture / widen margins
    p <- p + beta  * delta_recenter()      # short reset routine
elif barC < C_minus for longer than T_low:
    p <- p - eta * delta_down()            # relax toward efficient posture

apply_params(p)
\end{verbatim}

The exact \(\delta\) operators are platform-specific; what matters is the architecture: slow regulation of posture using a measured internal-cost signal.

\hypertarget{why-15-hz}{%
\subsubsection{5.4 Why 1--5 Hz}\label{why-15-hz}}

Many compensation phenomena are not instantaneous. They are regimes that persist over hundreds of milliseconds to seconds:

\begin{itemize}
\tightlist
\item
  stiffness escalation persists after a perturbation
\item
  planner override frequency stays elevated
\item
  estimator covariance can remain high
\end{itemize}

A slow regulator prevents the system from ``fighting itself'' by reacting on the same timescale as the low-level controller.

\hypertarget{critics-as-sensors-and-abstention-gating}{%
\subsubsection{5.5 Critics-as-sensors and abstention gating}\label{critics-as-sensors-and-abstention-gating}}

In many real deployments there is no online ``verifier'' that can certify whether a novel contact, terrain interaction, or recovery maneuver is truly safe and efficient. When we add learned critics (from demonstrations, simulation, or logged rollouts), the correct stance is not to treat them as authorities, but as additional sensors.

Operationally, use \textbf{abstention / tie mass} as a first-class uncertainty signal. Let \(\bar u_{J}(t)\) be a low-pass filtered version of \(u_{J}(t)\) on the same regime timescale as \(\bar C(t)\). When \(\bar u_{J}(t)\) rises, the regulator should \emph{tighten posture} (reduce speed/force envelopes, widen safety margins, shorten horizons) and preferentially invoke low-impact routines (recenter, re-estimate, re-localize) until confidence returns. Persistent abstention should downgrade the system into a conservative controller or safe mode rather than forcing additional ``clever'' action.

A minimal gating rule (illustrative):

\begin{quote}
if \(\bar C(t)\) is high \emph{or} \(\bar u_{J}(t)\) is high: tighten posture; prefer recenter/sense actions; add hysteresis.\\
if either persists past a time limit: switch to conservative safety controller / stop.
\end{quote}

Governance clause: learned critics can drift and can be gamed. They should be \textbf{versioned, monitored, and replay-tested} (a small fixed scenario suite) in the same way the telemetry\(\rightarrow\)posture mapping is monitored. When critic health is unknown, degrade to conservative heuristics and envelopes (fail closed).
\noindent\textbf{Phase-discipline reproducibility hook.} Treat irreversible writes/actuation as transition-window events: commit only in low-compensation windows, cap override duration, and require rollbackable recovery when windows are missed. This ``write when stable'' discipline reduces irreproducible flailing and preserves auditability under perturbation.
\noindent\textbf{Phase-discipline commitment-integrity hook.} If evidence is unchanged, posture must not silently revert. Any stance reversal in a commit window requires explicit change-basis logging (new evidence, discovered constraint, or explicit prior error), otherwise the regulator should withhold commit rights and route to gather/recenter.
\noindent\textbf{Phase-discipline commit windows.} Commit windows require telemetry and should open only when strain and uncertainty signals are within bounded posture limits. The selection gate is the upstream posture controller: when telemetry degrades, it withholds commit rights and routes the system to evidence-gathering or recovery instead.

\hypertarget{why-this-improves-energy-and-robustness}{%
\subsection{6. Why this improves energy and robustness}\label{why-this-improves-energy-and-robustness}}

\hypertarget{convex-energy-argument}{%
\subsubsection{6.1 Convex energy argument}\label{convex-energy-argument}}

For many systems, energy/power increases nonlinearly with control effort (e.g., torque, current, switching losses). If power \(P\) is convex in effective effort \(e(t)\), then reducing time spent at high effort yields disproportionate energy savings.

Let \(e(t)\) be an effort proxy correlated with \(\bar C(t)\). Total energy:

\[
E = \int_0^T P(e(t))\,dt
\]

If \(P\) is convex, then flattening spikes and reducing duty cycle in the high-effort regime reduces \(E\) more than proportional to mean effort reduction.

\hypertarget{robustness-via-internal-cycling}{%
\subsubsection{6.2 Robustness via internal cycling}\label{robustness-via-internal-cycling}}

Many brittle failures arise from chronic over-activation:

\begin{itemize}
\tightlist
\item
  saturation cascades
\item
  estimator divergence under sustained churn
\item
  contact instability amplified by high-frequency correction
\end{itemize}

A system that can downshift out of compensation faster will:

\begin{itemize}
\tightlist
\item
  recover quicker after disturbances
\item
  reduce thermal/actuator stress accumulation
\item
  avoid thrash loops that amplify errors
\end{itemize}

\hypertarget{experimental-directions}{%
\subsection{7. Experimental directions}\label{experimental-directions}}

The claims here are intended to be falsifiable with modest instrumentation.

\hypertarget{core-prediction}{%
\subsubsection{7.1 Core prediction}\label{core-prediction}}

At comparable task success, adding a baseline regulator that reduces compensation duty cycle should produce:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  lower energy per task (or per meter)
\item
  lower peak torque/current and thermal stress proxies
\item
  fewer catastrophic failures under perturbation
\item
  faster recovery time after disturbances
\item
  smoother degradation under resource constraints (battery, compute)
\end{enumerate}

\hypertarget{experiment-a-locomotion-under-perturbation}{%
\subsubsection{7.2 Experiment A: locomotion under perturbation}\label{experiment-a-locomotion-under-perturbation}}

\textbf{Setup}: biped or quadruped on variable terrain with external pushes and friction variation.

\textbf{Conditions}: - A1: baseline controller/planner only - A2: same controller + compensation index + baseline regulator

\textbf{Metrics}: - Joules/meter, peak current, temperature rise - slip/fall rate under perturbation - recovery time to stable gait - compensation duty cycle \(\operatorname{DC}\)

\textbf{Negative test}: if \(\operatorname{DC}\) decreases but energy does not, the claimed link between regime regulation and efficiency is weakened.

\hypertarget{experiment-b-manipulation-with-contact-uncertainty}{%
\subsubsection{7.3 Experiment B: manipulation with contact uncertainty}\label{experiment-b-manipulation-with-contact-uncertainty}}

\textbf{Setup}: insertion, door opening, or tool use with variable friction and compliance.

\textbf{Metrics}: - contact slip/impulse rate - jerk and force spikes - replanning/override bursts - success rate vs energy

\textbf{Negative test}: if regulator reduces compensation but increases failures or induces oscillatory cycling, the design must incorporate better hysteresis or context gating.

\hypertarget{experiment-c-sensor-degradation-latency-shift}{%
\subsubsection{7.4 Experiment C: sensor degradation / latency shift}\label{experiment-c-sensor-degradation-latency-shift}}

\textbf{Setup}: mobile robot or drone with induced sensor noise/latency.

\textbf{Hypothesis}: compensation manifests as estimator churn + control chatter.

\textbf{Metrics}: - covariance/prediction-error integrated - control-rate increase - energy and stability

\hypertarget{relation-to-existing-control-patterns}{%
\subsection{8. Relation to existing control patterns}\label{relation-to-existing-control-patterns}}

This paper does not claim novelty in hierarchical control or impedance control per se. The proposed contribution is the explicit \textbf{regime-level variable} and \textbf{slow regulatory layer}:

\medskip
Viewed through a more general regulation lens, \(\bar C(t)\) (optionally augmented with \(\bar u_{J}(t)\)) is simply a scalar \emph{restraint / strain telemetry} that drives posture. The meta-parameters \(p(t)\) correspond to an operating band (tight vs loose envelopes), and the recenter/safe-mode routines correspond to explicit recovery transitions. In other words, this is an embodied instantiation of ``regulation as a ground condition'': measure internal strain, gate risky actions under uncertainty, and bias the system back toward low-compensation basins.

\begin{itemize}
\tightlist
\item
  Hierarchical stacks exist, but often lack an explicit ``time in compensation'' signal.
\item
  Safety layers exist, but often do not regulate \emph{posture} back toward coordination once safe.
\item
  Many systems can enter compensation; fewer can reliably and quickly exit.
\end{itemize}

\hypertarget{limitations-and-scope}{%
\subsection{9. Limitations and scope}\label{limitations-and-scope}}

\begin{itemize}
\tightlist
\item
  \textbf{Domain specificity}: the best \(C(t)\) terms differ by platform; a single universal index is unlikely.
\item
  \textbf{Safety tradeoffs}: reducing stiffness is not always appropriate; the regulator must be constraint-aware.
\item
  \textbf{Tuning}: poor hysteresis can introduce oscillatory cycling (a new kind of thrash).
\item
  \textbf{Observability}: some systems lack sensors for reliable covariance/slip/torque estimation.
\item
  \textbf{Critic governance}: learned critics (if used) can drift, be overconfident, or be adversarially induced. Treat them as telemetry; version and monitor them; maintain a replay-suite; and fail closed by tightening posture when critic health or agreement is poor.
\end{itemize}

\hypertarget{conclusion}{%
\subsection{10. Conclusion}\label{conclusion}}

We introduced a two-regime framing for embodied control: latent coordination versus compensation. Many failures and inefficiencies arise not because robots cannot compensate, but because they lack an explicit mechanism to detect and regulate prolonged compensation.

By defining a measurable compensation index and adding a slow baseline regulator layer, we obtain a falsifiable architectural hypothesis: \textbf{systems that reduce compensation duty cycle should use less energy and be more robust under perturbation at comparable task performance}.

\noindent\textbf{Cross-cutting principle.} Coherence requires support: regulation specifies and maintains the supports that keep behavior aligned, perturbation-tolerant, and recoverable.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{appendix-a-practical-implementation-notes}{%
\subsection{Appendix A: Practical implementation notes}\label{appendix-a-practical-implementation-notes}}

\hypertarget{a.1-computing-ct-from-logs}{%
\subsubsection{\texorpdfstring{A.1 Computing \(C(t)\) from logs}{A.1 Computing C(t) from logs}}\label{a.1-computing-ct-from-logs}}

Minimal viable index for many robots:

\[
C(t) = w_\tau\,\|\tau(t)\|^2 + w_{\dot u}\,\|\dot u(t)\|^2 + w_{\text{sat}}\,r_{\text{sat}}(t)
\]

Add terms as available: - covariance/prediction error - slip/contact instability - replanning/override counters - critic abstention/tie mass \(u_{J}(t)\) (if using learned monitors)

\hypertarget{a.2-a-simple-recenter-routine-platform-agnostic}{%
\subsubsection{A.2 A simple ``recenter'' routine (platform-agnostic)}\label{a.2-a-simple-recenter-routine-platform-agnostic}}

A recenter routine is a brief protocol to restore coupling:

\begin{itemize}
\tightlist
\item
  pause high-level corrections for a short window
\item
  re-estimate state / reset filter if needed
\item
  re-sync phase variables (gait/CPG) if applicable
\item
  ramp impedance back smoothly
\end{itemize}

\hypertarget{a.3-mapping-to-a-general-internal-load-variable}{%
\subsubsection{A.3 Mapping to a general internal-load variable}\label{a.3-mapping-to-a-general-internal-load-variable}}

If you already track an internal load \(x(t)\) (activation/effort), treat \(\bar C(t)\) as a robotics-specific estimator of \(x(t)\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{appendix-b-suggested-figures}{%
\subsection{Appendix B: Suggested figures}\label{appendix-b-suggested-figures}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \textbf{State-space sketch}: latent coordination basin vs compensation basin, with arrows showing regulator bias back toward coordination.
\item
  \textbf{Time-series plot}: \(\bar C(t)\), \(H(t)\), and energy proxy over a perturbation event (with/without regulator).
\item
  \textbf{Energy vs duty-cycle}: energy per task vs \(\operatorname{DC}\) across trials.
\end{enumerate}
\newpage

{
\noindent\textbf{Note on authorship and tools:}\\
This work was developed through iterative reasoning, modeling, and synthesis.
Large language models were used as a collaborative tool to assist with drafting,
clarification, and cross-domain translation. All conceptual framing, structure,
and final judgments remain the responsibility of the author.
}

\end{document}
